{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sacred import Experiment\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import Datasets\n",
    "from Input import Input as Input\n",
    "from Input import batchgenerators as batchgen\n",
    "import Models.WGAN_Critic\n",
    "import Models.Unet\n",
    "import Utils\n",
    "import cPickle as pickle\n",
    "import Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsd_train, dsd_test = Datasets.getDSDFilelist(\"DSD100.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dict()\n",
    "dataset[\"train_sup\"] = dsd_train # 50 training tracks from DSD100 as supervised dataset\n",
    "dataset[\"train_unsup\"] = [] # Initialise unsupervised dateaset structure (fill up later)\n",
    "dataset[\"valid\"] = [dsd_test[0][:25], dsd_test[1][:25], dsd_test[2][:25]] # Validation and test contains 25 songs of DSD each, plus more (added later)\n",
    "dataset[\"test\"] = [dsd_test[0][25:], dsd_test[1][25:], dsd_test[2][25:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip up all paired dataset partitions so we have (mixture, accompaniment, drums) tuples\n",
    "dataset[\"train_sup\"] = zip(dataset[\"train_sup\"][0], dataset[\"train_sup\"][1], dataset[\"train_sup\"][2])\n",
    "dataset[\"valid\"] = zip(dataset[\"valid\"][0], dataset[\"valid\"][1], dataset[\"valid\"][2])\n",
    "dataset[\"test\"] = zip(dataset[\"test\"][0], dataset[\"test\"][1], dataset[\"test\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sample import Sample\n",
    "import glob\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train_unsup'] = [] #list of tuples of sample objects (mix, acc, drums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_mix = [] \n",
    "for i in range(1, 40):\n",
    "    unsup_mix.append(Sample.from_path('/home/ubuntu/AAS/data/unsup/mix/' + str(i) + '.mp3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load drums\n",
    "unsup_drums = [] \n",
    "for i in range(1, 178):\n",
    "    unsup_drums.append(Sample.from_path('/home/ubuntu/AAS/data/unsup/drums/' + str(i) + '.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def add_audio(audio_list, path_postfix):\n",
    "    '''\n",
    "    Reads in a list of audio files, sums their signals, and saves them in new audio file which is named after the first audio file plus a given postfix string\n",
    "    :param audio_list: List of audio file paths\n",
    "    :param path_postfix: Name to append to the first given audio file path in audio_list which is then used as save destination\n",
    "    :return: Audio file path where the sum signal was saved\n",
    "    '''\n",
    "    save_path = audio_list[0] + \"_\" + path_postfix + \".wav\"\n",
    "    if not os.path.exists(save_path):\n",
    "        for idx, instrument in enumerate(audio_list):\n",
    "            instrument_audio, sr = librosa.load(instrument, sr=None)\n",
    "            if idx == 0:\n",
    "                audio = instrument_audio\n",
    "            else:\n",
    "                audio += instrument_audio\n",
    "        if np.min(audio) < -1.0 or np.max(audio) > 1.0:\n",
    "            print(\"WARNING: Mixing tracks together caused the result to have sample values outside of [-1,1]. Clipping those values\")\n",
    "            audio = np.minimum(np.maximum(audio, -1.0), 1.0)\n",
    "\n",
    "        librosa.output.write_wav(save_path, audio, sr)\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (9299374,) (9298956,) (9299374,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2abec39ccb20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maudio_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msummed_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0munsup_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummed_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-efae61844e80>\u001b[0m in \u001b[0;36madd_audio\u001b[0;34m(audio_list, path_postfix)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstrument_audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0maudio\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minstrument_audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WARNING: Mixing tracks together caused the result to have sample values outside of [-1,1]. Clipping those values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (9299374,) (9298956,) (9299374,) "
     ]
    }
   ],
   "source": [
    "#TODO: wrap this in a loop, check for num of folders in unsup/acc, check for num of files for inner loop\n",
    "path = '/home/ubuntu/AAS/data/unsup/acc/5/'\n",
    "audio_list = []\n",
    "for i in range(1,6):\n",
    "    audio_list.append(path + str(i) + '.wav') #TODO: check for filetype\n",
    "summed_path = add_audio(audio_list, \"a\")\n",
    "unsup_acc.append(Sample.from_path(summed_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Sample.Sample at 0x7f5f668426d0>,\n",
       " <Sample.Sample at 0x7f5f66740d10>,\n",
       " <Sample.Sample at 0x7f5f66842250>,\n",
       " <Sample.Sample at 0x7f5f66852090>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_acc.append(Sample.from_path('/home/ubuntu/AAS/data/unsup/acc/3/1.mp3'))\n",
    "unsup_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train_unsup'] = [unsup_mix, unsup_acc, unsup_drums]\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/AAS/data/unsup/acc/4/1.wav_.wav'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train_unsup'][1][2].path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset structure\n"
     ]
    }
   ],
   "source": [
    "with open('dataset.pkl', 'wb') as file:\n",
    "    pickle.dump(dataset, file)\n",
    "print(\"Created dataset structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/AAS/data/unsup/drums/177.wav'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsup_drums = unsup_mix[39:]\n",
    "# unsup_mix = unsup_mix[:39]\n",
    "unsup_drums[-1].path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replaced\n",
    "# root = '/home/ubuntu/AAS'\n",
    "# if dataset == 'train_unsup':\n",
    "#     mix_list = glob.glob(root+dataset+'/*.wav')\n",
    "#     voice_list = list()\n",
    "# else:\n",
    "#     mix_list = glob.glob(root+dataset+'/Mixed/*.wav')\n",
    "#     voice_list = glob.glob(root+dataset+'/Drums/*.wav')\n",
    "# mix = list()\n",
    "# voice = list()\n",
    "# for item in mix_list:\n",
    "#     mix.append(Sample.from_path(item))\n",
    "# for item in voice_list:\n",
    "#     voice.append(Sample.from_path(item))\n",
    "# return mix, voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset['test'])):\n",
    "    for samp in dataset['test'][i]:\n",
    "        samp.path = '/home/ubuntu/AAS/' + samp.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Sample' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-fb265bed0ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_sup'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msamp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Sample' object is not iterable"
     ]
    }
   ],
   "source": [
    "for tup in dataset['train_sup']:\n",
    "    for samp in tup[0]:\n",
    "        print(samp.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/AAS/data/DSD100/Mixtures/Test/033 - Sambasevam Shanmugam - Kaathaadi/mixture.wav'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0][0].path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '__main__.pysndfile'; '__main__' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ac37f9eef0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpysndfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mformatinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msndfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpysndfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupported_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupported_endianness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupported_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyaudioException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyaudioIOError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.pysndfile'; '__main__' is not a package"
     ]
    }
   ],
   "source": [
    "from pysndfile import formatinfo, sndfile\n",
    "from pysndfile import supported_format, supported_endianness, supported_encoding, PyaudioException, PyaudioIOError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
